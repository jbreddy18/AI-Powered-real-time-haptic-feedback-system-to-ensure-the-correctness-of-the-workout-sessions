This Project is  presents a novel multi-scale multi-head attention-based stacked BiLSTM model for workout exercise recognition using IMU sensor data.  The study utilizes a dataset comprising 200 participants, each completing 10 distinct exercise tasks, resulting in a total of 2000 recorded sessions. The model addresses motion pattern variability and sensor orientation challenges by processing rotation-specific data through multiple attention heads, enabling robust classification. IMU data, including accelerometer, gyroscope, and magnetometer signals, was preprocessed and labeled for ten exercise types. Evaluated using 5-fold cross-validation, the proposed model outperformed traditional architectures like CNN+LSTM, BiLSTM, and single-head BiLSTM. It achieved an average accuracy of 95%, surpassing the 83.18% of non-multi-head models and 92.44% of multi-head BiLSTM without self-attention. The multi-head attention mechanism effectively captured spatial and temporal dependencies, minimizing misclassification and overfitting. The confusion matrix analysis confirmed precise classification, while rapid training convergence with validation accuracy exceeding 95% highlighted the modelâ€™s stability. These results demonstrate the model's potential for real-time fitness monitoring and rehabilitation, offering a reliable solution for wearable technology and intelligent health applications.
